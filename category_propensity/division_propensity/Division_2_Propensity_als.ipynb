{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Division Propensity Recommendation script     \n",
    "Last update: March 3,2021  \n",
    "Version 1.2   \n",
    "**Output format:** cmd_id | category | division_id | division | propensity_score | propensity_rank | next_best_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1302</td><td>application_1570493391423_69060</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-21-40-211.analytics.neimanmarcuscloud.net:20888/proxy/application_1570493391423_69060/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-21-43-72.analytics.neimanmarcuscloud.net:8042/node/containerlogs/container_1570493391423_69060_01_000003/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType,FloatType, StringType\n",
    "from pyspark.sql.functions import col, rank,concat, concat_ws, monotonically_increasing_id\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "sc.setCheckpointDir(\"s3://nmg-analytics-ds-prod/ds/dev/Users/nmdst400/checkpointdir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Code Parameters\n",
    "#brand = 'nm'\n",
    "#env = 'prod'\n",
    "#wbrand ='NM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_f='s3://nmg-analytics-ds-prod/ds/'+env+'/ClientConnect/CMD/data/'+brand+'/cust_division_rank.csv.gz'\n",
    "df=spark.read.option(\"header\",\"true\").csv(input_f, sep=',')\n",
    "\n",
    "df = df.withColumn('product', concat_ws('_','category','division_id','division'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexer1 = StringIndexer(inputCol=\"cmd_id\", outputCol=\"userID\")\n",
    "df_staging = indexer1.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexer2 = StringIndexer(inputCol=\"product\", outputCol=\"catID\")\n",
    "df_staging = indexer2.fit(df_staging).transform(df_staging)\n",
    "df_1=df_staging.selectExpr('userID','catID','cast(score as double) score')\n",
    "(train_set, validation_set) = df_1.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search optimal model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def tune_ALS(train_data, validation_data, maxIter, regParams, ranks):\n",
    "    \"\"\"\n",
    "    grid search function to select the best model based on RMSE of\n",
    "    validation data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: spark DF with columns ['userId', 'productId', 'rating']\n",
    "    validation_data: spark DF with columns ['userId', 'productId', 'rating']\n",
    "    maxIter: int, max number of learning iterations\n",
    "    regParams: list of float, one dimension of hyper-param tuning grid\n",
    "    ranks: list of float, one dimension of hyper-param tuning grid\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    The best fitted ALS model with lowest RMSE score on validation data\n",
    "    \"\"\"\n",
    "    # initial\n",
    "    \n",
    "    best_rank = -1\n",
    "    \n",
    "    best_regularization = 0\n",
    "    min_error = float('inf')\n",
    "    best_model = None\n",
    "    for rank in ranks:\n",
    "        for reg in regParams:\n",
    "            # get ALS model\n",
    "            als = ALS(userCol='userID', itemCol='catID', ratingCol='rating',implicitPrefs=False,coldStartStrategy=\"drop\").setMaxIter(maxIter).setRank(rank).setRegParam(reg)\n",
    "            # train ALS model\n",
    "            model = als.fit(train_data)\n",
    "            # evaluate the model by computing the RMSE on the validation data\n",
    "            predictions = model.transform(validation_data)\n",
    "            evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                            labelCol=\"rating\",\n",
    "                                            predictionCol=\"prediction\")\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "            print('{} latent factors (rank) and regularization = {}: validation RMSE is {}'.format(rank, reg, rmse))\n",
    "            if rmse < min_error:\n",
    "                \n",
    "                min_error = rmse\n",
    "                \n",
    "                best_rank = rank\n",
    "                best_regularization = reg\n",
    "                best_model = model\n",
    "    print('\\nThe best model has {} latent factors and regularization = {}'.format(best_rank, best_regularization))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "maxIter = 10\n",
    "regParams = [0.05,0.1]  # The best model has 3.0 latent factors and regularization = 0.05\n",
    "ranks = [ 3.0, 5.0]\n",
    "best_model = tune_ALS(train_set, validation_set, maxIter, regParams, ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(maxIter=10, rank= 3, regParam=0.05, implicitPrefs=False,coldStartStrategy=\"drop\",\\\n",
    "          userCol='userID', itemCol='catID', ratingCol='score')\n",
    "\n",
    "model = als.fit(train_set)\n",
    "#predictions = model.transform(validation_set)\n",
    "\n",
    "#evaluator = RegressionEvaluator(metricName=\"mae\", labelCol=\"score\", predictionCol=\"prediction\")\n",
    "#mae = evaluator.evaluate(predictions)\n",
    "\n",
    "#print(\"Mean Absolute Error \", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Recommendations for all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userID: integer (nullable = false)\n",
      " |-- recommendations: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- catID: integer (nullable = true)\n",
      " |    |    |-- rating: float (nullable = true)"
     ]
    }
   ],
   "source": [
    "# Generate top 10 recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(15)\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "userRecs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "userRecs_output=userRecs.select('userID',F.posexplode('recommendations')).select('userID','col.catID','pos','col.rating').checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "userIndex=df_staging.selectExpr('cast(userID as int) userID','cmd_id').distinct()\n",
    "catIndex=df_staging.selectExpr('cast(catID as int) catID','product').distinct()\n",
    "recs_df = userRecs_output.join(catIndex,userRecs_output.catID==catIndex.catID).select('userID','product','pos','rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recs_df = recs_df.join(userIndex,recs_df.userID==userIndex.userID).select('cmd_id','product','pos','rating')\n",
    "recs_df = recs_df.withColumnRenamed(\"pos\", \"propensity_rank\").withColumnRenamed(\"rating\",\"propensity_score\")\n",
    "recs_df = recs_df.withColumn(\"propensity_rank\",F.col(\"propensity_rank\")+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction scores returned by **ALS** with implicit feedbacks with Apache Spark aren't normalized to fit be between [0,1] or [see](https://stackoverflow.com/questions/46904078/spark-als-recommendation-system-have-value-prediction-greater-than-1). ALS uses stochastic gradient descent and approximations to compute (and re-compute) users and item factors on each step to minimize the cost function which allows it to scale.  \n",
    "As a matter of fact, normalizing those scores isn't relevant. The reason for this is actually that those scores doesn't mean much on their own. [refer](https://stackoverflow.com/questions/46462470/how-can-i-evaluate-the-implicit-feedback-als-algorithm-for-recommendations-in-ap/46490352#46490352)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling into range 1-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_recs, min_recs = recs_df.select(\"propensity_score\").rdd.max()[0], recs_df.select(\"propensity_score\").rdd.min()[0]\n",
    "recs_df= recs_df.withColumn(\"propensity_score\",(100-1)*(recs_df[\"propensity_score\"]- min_recs)/(max_recs-min_recs) + 1 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new key column to join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------+------------------+--------------------+\n",
      "|  cmd_id|             product|propensity_rank|  propensity_score|          id_product|\n",
      "+--------+--------------------+---------------+------------------+--------------------+\n",
      "| W75LuqZ|Women's Apparel_1...|              1| 61.12565059214503|W75LuqZWomen's Ap...|\n",
      "| W75LuqZ|Contemporary Appa...|              2| 60.37537201631657|W75LuqZContempora...|\n",
      "| W75LuqZ|    Beauty_53_Beauty|              3| 57.89019971226391|W75LuqZBeauty_53_...|\n",
      "| W75LuqZ|Gifts & Home_21_G...|              4| 56.76275366162963|W75LuqZGifts & Ho...|\n",
      "| W75LuqZ|Fine Apparel_81_F...|              5|56.128202654150016|W75LuqZFine Appar...|\n",
      "| W75LuqZ|Intimate Apparel_...|              6| 55.99478491577048|W75LuqZIntimate A...|\n",
      "| W75LuqZ|Ladies Shoes_34_L...|              7|55.555856982762336|W75LuqZLadies Sho...|\n",
      "| W75LuqZ|Children's_15_Chi...|              8| 55.24015338089912|W75LuqZChildren's...|\n",
      "| W75LuqZ|  Jewelry_56_Jewelry|              9| 54.34381112750101|W75LuqZJewelry_56...|\n",
      "| W75LuqZ|Designer Handbags...|             10| 52.37409716059366|W75LuqZDesigner H...|\n",
      "| W75LuqZ|      Men's_44_Men's|             11| 52.08021082672162|W75LuqZMen's_44_M...|\n",
      "| W75LuqZ|Fashion Accessori...|             12|51.583370058899945|W75LuqZFashion Ac...|\n",
      "| W75LuqZ|Non Retail_98_Non...|             13| 46.68605500815437|W75LuqZNon Retail...|\n",
      "| W75LuqZ|Last Call Direct ...|             14| 44.20233369044933|W75LuqZLast Call ...|\n",
      "| W75LuqZ|NMG Miscellaneous...|             15| 43.47340469047169|W75LuqZNMG Miscel...|\n",
      "|15WfIKQc|Women's Apparel_1...|              1| 59.05786272411833|15WfIKQcWomen's A...|\n",
      "|15WfIKQc|Contemporary Appa...|              2|  58.3052821903893|15WfIKQcContempor...|\n",
      "|15WfIKQc|    Beauty_53_Beauty|              3|55.276822726127826|15WfIKQcBeauty_53...|\n",
      "|15WfIKQc|Gifts & Home_21_G...|              4| 54.43774424210944|15WfIKQcGifts & H...|\n",
      "|15WfIKQc|Fine Apparel_81_F...|              5| 54.18667341261785|15WfIKQcFine Appa...|\n",
      "+--------+--------------------+---------------+------------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "recs_df = recs_df.withColumn(\"id_product\",F.concat(col('cmd_id'), col('product')))\n",
    "#recs_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Load data recent  historical trans data (default= 30 days) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_dir='s3://nmg-analytics-ds-prod/ds/'+env+'/ClientConnect/CMD/data/'+brand+'/'\n",
    "f = input_dir+'recent_history.csv.gz'\n",
    "df_recent=spark.read.option(\"header\",\"True\").csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_recent = df_recent.withColumn('product',concat_ws('_','division','division_id','division')).select('cmd_id','product')\n",
    "df_recent = df_recent.withColumn(\"id_product\",F.concat(col('cmd_id'), col('product')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find cmd_id with category (in recommendation list) have not purchased before (in 3 year hist trans)\n",
    "df_recent = recs_df.join(df_recent ,recs_df.id_product == df_recent.id_product, \"leftanti\")\n",
    "df_recent = df_recent.selectExpr('cmd_id','product','propensity_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Re_order after merge\n",
    "df_recent = df_recent.orderBy(F.col(\"cmd_id\"),F.col(\"propensity_score\").desc())\n",
    "df_recent = df_recent.selectExpr(\"cmd_id\", \"product\",\"propensity_score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "window = Window.partitionBy(df_recent['cmd_id']).orderBy(df_recent['propensity_score'].desc())\n",
    "df_recent = df_recent.select('*', F.row_number().over(window).alias('next_best_rank'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7752fd9a87db4149a367988bc79148f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recs_df = recs_df.selectExpr('cmd_id','product','propensity_score','propensity_rank')\n",
    "recs_df = recs_df.join(df_recent.selectExpr('cmd_id','product','next_best_rank'),['cmd_id','product'],how='left')\n",
    "recs_df= recs_df.orderBy(F.col(\"cmd_id\"),F.col(\"propensity_score\").desc(),F.col(\"next_best_rank\"))\n",
    "#recs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recent = recs_df.select(F.split(recs_df.product,\"_\")).rdd.flatMap(\n",
    "              lambda x: x).toDF(schema=[\"col1\",\"col2\",\"col3\"])\n",
    "\n",
    "df_recent = df_recent.withColumn(\"id\", monotonically_increasing_id())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_df = recs_df.withColumn(\"id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_df = recs_df.join(df_recent, df_recent.id== recs_df.id).drop(\"id\")\n",
    "recs_df = recs_df.withColumnRenamed('col1','category').withColumnRenamed('col2','division_id').withColumnRenamed('col3','division')\n",
    "recs_df = recs_df.orderBy(F.col(\"cmd_id\"),F.col(\"propensity_score\").desc(),F.col(\"next_best_rank\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_df = recs_df.select('cmd_id','category','division_id','division','propensity_score','propensity_rank','next_best_rank')\n",
    "#recs_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recs_df.write.parquet(\"s3a://nmg-analytics-ds-prod/ds/{0}/product_propensity/{1}/output/division_propensity/\".format(env,brand),mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def renormalize(n, range1, range2):\n",
    "    delta1 = range1[1] - range1[0]\n",
    "    delta2 = range2[1] - range2[0]\n",
    "    return (delta2 * (n - range1[0]) / delta1) + range2[0]\n",
    "renormalize(8, [1,9.7], [1,5])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "normalizeUDF = F.udf(lambda z: renormalize(z,[min_rating, max_rating],[1,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
